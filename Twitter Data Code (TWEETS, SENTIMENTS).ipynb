{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to extract events tweets and their sentiments from Twitter API\n",
    "\n",
    "This script will first load in <b>eventbritedatapastevents.csv</b> which contains all the past 28 events in the 31 LGAs. Based on this list, requests will then be made to Twitter API to get the tweets relevant to the events based on the event name and/or description. Note that this has to be done manually as different event has their own names/descriptions format. 1000 tweets were requested within 400 miles distance of the latitude and longitude of Victoria as event participants can come from anywhere in Victoria, not necessarily just in the locality the event was held. Note that due to the restriction of Twitter Public API, only tweets tweeted in the last 7 days will be received.\n",
    "\n",
    "Afterwhich, text cleaning will be done to the tweets message and sentiment analysis will then be carried out using `get_sentiments('nrc')` which will generate the sentiments of each token/word in the tweets message to one of the 10 sentiment categories mainly, <b>anger, anticipation, disgust, fear, joy, negative, positive, sadness, surprise, trust</b>. Once done, this script will output the tweets message together with their sentiments, and another dataframe containing the percentages of sentiments in each event for further usage in Microsoft Power BI visualisation.\n",
    "\n",
    "### Output Documents\n",
    "1. <b>TWEETS.csv</b> - contains relevant tweets messages on the past events in 31 LGAs and their sentiments\n",
    "2. <b>SENTIMENTS.csv</b> - contains percentages of sentiments for each past event in 31 LGAs\n",
    "\n",
    "### Note\n",
    "- Manual input required in <b>Setup Twitter Connection</b> with the `consumer_key`, `consumer_secret`, `access_token` and `access_secret` obtained from Twitter Developers Website with individual account\n",
    "- Before loading in `eventbritedatapastevents.csv`, ensure that manual input of `search_string` has been done in Microsoft Excel in order to search for the relevant tweets pertaining to each event.\n",
    "- Ensure that `eventbritedatapastevents.csv` is in the same directory as this script so the dataset can be loaded in accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Twitter Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary library for Twitter API, data manipulation and text cleaning\n",
    "library(\"twitteR\")\n",
    "library(\"ROAuth\")\n",
    "library(\"dplyr\")\n",
    "library(\"tidytext\")\n",
    "library(\"stringr\")\n",
    "library(\"tidyr\")\n",
    "\n",
    "# Set up Twitter Connection\n",
    "consumer_key <- ''                               ############### INPUT TWITTER DEVELOPER API TOKENS HERE ###############\n",
    "consumer_secret<- ''\n",
    "access_token <- ''\n",
    "access_secret <- ''\n",
    "setup_twitter_oauth(consumer_key ,consumer_secret,access_token ,access_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1 - Extract tweets and populate sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in list of past 28 days events in the 31 LGAs\n",
    "events = read.csv(\"./eventbritedatapastevents.csv\", header = TRUE)\n",
    "\n",
    "options(warn=-1)\n",
    "# store the 10 sentiments in a vector first\n",
    "all_sen_list = c('anger','anticipation','disgust','fear','joy','negative','positive','sadness','surprise','trust')\n",
    "# set flag for ease of storage\n",
    "flag = 0\n",
    "# empty vector to store events that contain no tweets\n",
    "no_tweets_events = c()\n",
    "\n",
    "# loop through each of the past event\n",
    "for (i in 1:nrow(events)){\n",
    "    # request from Twitter API based on search_string, no of tweets 1000, lat and lon of Victoria with 400 miles distance\n",
    "    tweets <- searchTwitter(as.character(events$search_string[i]), n=1000, geocode='-37.4713,144.7852,400mi',lang = 'en')\n",
    "    # process only if there are relevant tweets for this event\n",
    "    if (length(tweets)!=0){\n",
    "            # convert to dataframe and do text cleaning on the tweets text\n",
    "            df <- twListToDF(tweets)\n",
    "            df$text=as.character(df$text)\n",
    "            df$text <- gsub(\"\\\\$\", \"\", df$text) \n",
    "            df$text <- gsub(\"@\\\\w+\", \"\", df$text)\n",
    "            df$text <- gsub(\"[[:punct:]]\",\"\", df$text)\n",
    "            df$statusSource <- gsub(\"http\\\\w+\", \"\", df$statusSource)\n",
    "            df$text <- gsub(\"[ |\\t]{2,}\", \"\", df$text)\n",
    "            df$text <- gsub(\"^ \", \"\", df$text)\n",
    "            df$text <- gsub(\" $\", \"\", df$text)\n",
    "            text_df <- data_frame(id=df$id, text = df$text) %>% unnest_tokens(word, text)\n",
    "            # if this is the first event, create TWEETS and SENTIMENTS\n",
    "            if (flag == 0){\n",
    "                # populate the sentiment for each token/word\n",
    "                TWEETS <- df %>% left_join(text_df %>% inner_join(get_sentiments(\"nrc\")))\n",
    "                # remove the word with NA sentiment\n",
    "                TWEETS <- subset(TWEETS, sentiment!=\"NA\")\n",
    "                # add in event name and LGA\n",
    "                TWEETS['event'] <- as.character(events$name[i])\n",
    "                TWEETS['LGA'] <- as.character(events$LGA[i])\n",
    "                \n",
    "                # create the SENTIMENTS dataframe which contain the % of the sentiments based on all words/tokens\n",
    "                SENTIMENTS <- TWEETS %>% count(sentiment, id)\n",
    "                # set the count of each sentiment to 1 as one tweet can have words of similar sentiments \n",
    "                SENTIMENTS['n'] <- 1\n",
    "                # spread the dataframe to sentiments as the column headers\n",
    "                SENTIMENTS <- SENTIMENTS %>% count(sentiment) %>% spread(sentiment, n)\n",
    "                # get the percentages by dividing by the number of tweets for this event\n",
    "                SENTIMENTS <- (SENTIMENTS/length(unique(TWEETS$created)))*100\n",
    "                # append a 0% to sentiments not present in this event based on the earlier defined all_sen_list\n",
    "                for (each in all_sen_list){\n",
    "                    if (!(each %in% colnames(SENTIMENTS))){\n",
    "                        SENTIMENTS[each] <- 0\n",
    "                    }\n",
    "                }\n",
    "                # add in event name, LGA, event date, culture category\n",
    "                SENTIMENTS['event'] <- as.character(events$name[i])\n",
    "                SENTIMENTS['LGA'] <- as.character(events$LGA[i])\n",
    "                SENTIMENTS['start_date'] <- as.character(events$start_date[i])\n",
    "                SENTIMENTS['category'] <- as.character(events$category[i])\n",
    "                # change flag to 1 so that TWEETS and SENTIMENTS will not be created again\n",
    "                flag = 1\n",
    "                }\n",
    "            # repeat the above but create TWEETS_temp and SENTIMENTS_temp, and rbind to TWEETS and SENTIMENTS afterwhich\n",
    "            else{\n",
    "                TWEETS_temp <- df %>% left_join(text_df %>% inner_join(get_sentiments(\"nrc\")))\n",
    "                TWEETS_temp <- subset(TWEETS_temp, sentiment!=\"NA\")\n",
    "                if (nrow(TWEETS_temp)!=0){\n",
    "                    TWEETS_temp['event'] <- as.character(events$name[i])\n",
    "                    TWEETS_temp['LGA'] <- as.character(events$LGA[i])\n",
    "                    TWEETS <- rbind(TWEETS, TWEETS_temp)\n",
    "\n",
    "                    SENTIMENTS_temp <- TWEETS_temp %>% count(sentiment, id)\n",
    "                    SENTIMENTS_temp['n'] <- 1\n",
    "                    SENTIMENTS_temp <- SENTIMENTS_temp %>% count(sentiment) %>% spread(sentiment, n)\n",
    "                    SENTIMENTS_temp <- (SENTIMENTS_temp/length(unique(TWEETS_temp$created)))*100\n",
    "                    for (each in all_sen_list){\n",
    "                        if (!(each %in% colnames(SENTIMENTS_temp))){\n",
    "                            SENTIMENTS_temp[each] <- 0\n",
    "                        }\n",
    "                    }\n",
    "                    SENTIMENTS_temp['event'] <- as.character(events$name[i])\n",
    "                    SENTIMENTS_temp['LGA'] <- as.character(events$LGA[i])\n",
    "                    SENTIMENTS_temp['start_date'] <- as.character(events$start_date[i])\n",
    "                    SENTIMENTS_temp['category'] <- as.character(events$category[i])\n",
    "                    SENTIMENTS <- rbind(SENTIMENTS, SENTIMENTS_temp)\n",
    "                    }\n",
    "                # if this event has no relevant tweet, append the name to the no_tweets_events vector\n",
    "                else{\n",
    "                    no_tweets_events = c(no_tweets_events, as.character(events$name[i]))\n",
    "                }\n",
    "                }\n",
    "            }\n",
    "    # if this event has no relevant tweet, append the name to the no_tweets_events vector\n",
    "    else{\n",
    "        no_tweets_events = c(no_tweets_events, as.character(events$name[i]))\n",
    "    }\n",
    "}\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 - Output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the 2 dataframes into .csv files\n",
    "write.csv(TWEETS, './TWEETS.csv',row.names = FALSE)\n",
    "write.csv(SENTIMENTS, './SENTIMENTS.csv',row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------- END OF SCRIPT --------------------------------------#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
